{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Data\n",
    "* An experimental drug was tested on individuals from ages 10 to 100.\n",
    "* The trail had 2000 participates.\n",
    "* Half were under 50, half older.\n",
    "* 80% of younger half have negetive results.\n",
    "* 80% of older hald have positive results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "younger = np.random.randint(10, 51, size=1000).reshape(-1, 1)\n",
    "older = np.random.randint(51, 100, size=1000).reshape(-1, 1)\n",
    "train_samples = np.concatenate((younger, older), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "younger = np.random.choice(2, size=1000, p=[0.8,0.2]).reshape(-1, 1)\n",
    "older = np.random.choice(2, size=1000, p=[0.2,0.8]).reshape(-1, 1)\n",
    "train_labels = np.concatenate((younger, older), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = np.arange(2000)\n",
    "np.random.shuffle(shuffle)\n",
    "scaled_train_samples = scaled_train_samples[shuffle]\n",
    "train_labels = train_labels[shuffle]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three-layer NN with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.7037 - acc: 0.5033 - val_loss: 0.6956 - val_acc: 0.4650\n",
      "Epoch 2/20\n",
      "1800/1800 [==============================] - 0s 167us/step - loss: 0.6883 - acc: 0.6233 - val_loss: 0.6816 - val_acc: 0.6050\n",
      "Epoch 3/20\n",
      "1800/1800 [==============================] - 0s 168us/step - loss: 0.6738 - acc: 0.6372 - val_loss: 0.6687 - val_acc: 0.6150\n",
      "Epoch 4/20\n",
      "1800/1800 [==============================] - 0s 170us/step - loss: 0.6605 - acc: 0.6850 - val_loss: 0.6568 - val_acc: 0.6250\n",
      "Epoch 5/20\n",
      "1800/1800 [==============================] - 0s 171us/step - loss: 0.6480 - acc: 0.6839 - val_loss: 0.6472 - val_acc: 0.6400\n",
      "Epoch 6/20\n",
      "1800/1800 [==============================] - 0s 172us/step - loss: 0.6366 - acc: 0.7072 - val_loss: 0.6386 - val_acc: 0.6850\n",
      "Epoch 7/20\n",
      "1800/1800 [==============================] - 0s 166us/step - loss: 0.6253 - acc: 0.7339 - val_loss: 0.6299 - val_acc: 0.7150\n",
      "Epoch 8/20\n",
      "1800/1800 [==============================] - 0s 174us/step - loss: 0.6142 - acc: 0.7433 - val_loss: 0.6217 - val_acc: 0.7450\n",
      "Epoch 9/20\n",
      "1800/1800 [==============================] - 0s 170us/step - loss: 0.6036 - acc: 0.7583 - val_loss: 0.6141 - val_acc: 0.7450\n",
      "Epoch 10/20\n",
      "1800/1800 [==============================] - 0s 161us/step - loss: 0.5934 - acc: 0.7622 - val_loss: 0.6077 - val_acc: 0.7450\n",
      "Epoch 11/20\n",
      "1800/1800 [==============================] - 0s 166us/step - loss: 0.5836 - acc: 0.7811 - val_loss: 0.6016 - val_acc: 0.7450\n",
      "Epoch 12/20\n",
      "1800/1800 [==============================] - 0s 172us/step - loss: 0.5746 - acc: 0.7856 - val_loss: 0.5964 - val_acc: 0.7550\n",
      "Epoch 13/20\n",
      "1800/1800 [==============================] - 0s 173us/step - loss: 0.5653 - acc: 0.7939 - val_loss: 0.5912 - val_acc: 0.7700\n",
      "Epoch 14/20\n",
      "1800/1800 [==============================] - 0s 168us/step - loss: 0.5580 - acc: 0.7978 - val_loss: 0.5884 - val_acc: 0.7650\n",
      "Epoch 15/20\n",
      "1800/1800 [==============================] - 0s 174us/step - loss: 0.5524 - acc: 0.7967 - val_loss: 0.5856 - val_acc: 0.7700\n",
      "Epoch 16/20\n",
      "1800/1800 [==============================] - 0s 170us/step - loss: 0.5480 - acc: 0.8011 - val_loss: 0.5841 - val_acc: 0.7650\n",
      "Epoch 17/20\n",
      "1800/1800 [==============================] - 0s 161us/step - loss: 0.5442 - acc: 0.7956 - val_loss: 0.5834 - val_acc: 0.7650\n",
      "Epoch 18/20\n",
      "1800/1800 [==============================] - 0s 165us/step - loss: 0.5412 - acc: 0.7972 - val_loss: 0.5820 - val_acc: 0.7650\n",
      "Epoch 19/20\n",
      "1800/1800 [==============================] - 0s 169us/step - loss: 0.5387 - acc: 0.7933 - val_loss: 0.5816 - val_acc: 0.7650\n",
      "Epoch 20/20\n",
      "1800/1800 [==============================] - 0s 168us/step - loss: 0.5366 - acc: 0.7933 - val_loss: 0.5814 - val_acc: 0.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f247c324160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "younger = np.random.randint(10, 51, size=100).reshape(-1, 1)\n",
    "older = np.random.randint(51, 100, size=100).reshape(-1, 1)\n",
    "test_samples = np.concatenate((younger, older), axis = 0)\n",
    "younger = np.random.choice(2, size=100, p=[0.8,0.2]).reshape(-1, 1)\n",
    "older = np.random.choice(2, size=100, p=[0.2,0.8]).reshape(-1, 1)\n",
    "test_labels = np.concatenate((younger, older), axis=0)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform(test_samples)\n",
    "shuffle = np.arange(200)\n",
    "np.random.shuffle(shuffle)\n",
    "scaled_test_samples = scaled_test_samples[shuffle]\n",
    "test_labels = test_labels[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18870538, 0.8112946 ],\n",
       "       [0.15671636, 0.84328365],\n",
       "       [0.2353095 , 0.76469046],\n",
       "       [0.18870538, 0.8112946 ],\n",
       "       [0.77683985, 0.22316015],\n",
       "       [0.6627503 , 0.33724973],\n",
       "       [0.16004008, 0.83996   ],\n",
       "       [0.61976993, 0.38023016],\n",
       "       [0.17751841, 0.8224816 ],\n",
       "       [0.22814655, 0.77185345],\n",
       "       [0.39020652, 0.6097935 ],\n",
       "       [0.412669  , 0.587331  ],\n",
       "       [0.56336194, 0.4366381 ],\n",
       "       [0.2045382 , 0.79546183],\n",
       "       [0.6627503 , 0.33724973],\n",
       "       [0.67311895, 0.3268811 ],\n",
       "       [0.26799503, 0.732005  ],\n",
       "       [0.69334984, 0.3066502 ],\n",
       "       [0.5169471 , 0.48305294],\n",
       "       [0.1925526 , 0.8074474 ],\n",
       "       [0.2219027 , 0.77809733],\n",
       "       [0.76667297, 0.23332709],\n",
       "       [0.69334984, 0.3066502 ],\n",
       "       [0.5975026 , 0.40249744],\n",
       "       [0.7223361 , 0.27766383],\n",
       "       [0.42404452, 0.57595545],\n",
       "       [0.52861   , 0.47138998],\n",
       "       [0.5402417 , 0.45975822],\n",
       "       [0.1739069 , 0.82609314],\n",
       "       [0.36820018, 0.6317998 ],\n",
       "       [0.4586101 , 0.54138994],\n",
       "       [0.7723132 , 0.22768682],\n",
       "       [0.401386  , 0.59861404],\n",
       "       [0.7778341 , 0.22216584],\n",
       "       [0.33621708, 0.66378295],\n",
       "       [0.7776699 , 0.22233008],\n",
       "       [0.5518299 , 0.44817016],\n",
       "       [0.401386  , 0.59861404],\n",
       "       [0.7406944 , 0.25930554],\n",
       "       [0.7739004 , 0.22609961],\n",
       "       [0.20043911, 0.79956084],\n",
       "       [0.22814655, 0.77185345],\n",
       "       [0.15671636, 0.84328365],\n",
       "       [0.7743543 , 0.22564568],\n",
       "       [0.20043911, 0.79956084],\n",
       "       [0.77577007, 0.22422992],\n",
       "       [0.22814655, 0.77185345],\n",
       "       [0.77626646, 0.2237335 ],\n",
       "       [0.26799503, 0.732005  ],\n",
       "       [0.68332106, 0.31667894],\n",
       "       [0.3258646 , 0.6741354 ],\n",
       "       [0.37914118, 0.6208588 ],\n",
       "       [0.48189846, 0.51810163],\n",
       "       [0.1668583 , 0.8331417 ],\n",
       "       [0.3258646 , 0.6741354 ],\n",
       "       [0.6522227 , 0.34777725],\n",
       "       [0.2045382 , 0.79546183],\n",
       "       [0.36820015, 0.6317998 ],\n",
       "       [0.52861005, 0.47138998],\n",
       "       [0.70319897, 0.29680103],\n",
       "       [0.2219027 , 0.77809733],\n",
       "       [0.7723132 , 0.22768682],\n",
       "       [0.21720725, 0.7827928 ],\n",
       "       [0.48189846, 0.51810163],\n",
       "       [0.7697059 , 0.23029412],\n",
       "       [0.5169471 , 0.4830529 ],\n",
       "       [0.20043911, 0.79956084],\n",
       "       [0.2219027 , 0.77809733],\n",
       "       [0.5748259 , 0.42517415],\n",
       "       [0.7316147 , 0.26838532],\n",
       "       [0.18118857, 0.8188115 ],\n",
       "       [0.6522227 , 0.34777725],\n",
       "       [0.401386  , 0.59861404],\n",
       "       [0.56336194, 0.4366381 ],\n",
       "       [0.15023777, 0.8497622 ],\n",
       "       [0.77683985, 0.22316015],\n",
       "       [0.60869277, 0.39130723],\n",
       "       [0.5402417 , 0.45975822],\n",
       "       [0.7778341 , 0.22216584],\n",
       "       [0.5169471 , 0.48305294],\n",
       "       [0.71286273, 0.2871372 ],\n",
       "       [0.2219027 , 0.77809733],\n",
       "       [0.33621708, 0.66378295],\n",
       "       [0.5169471 , 0.4830529 ],\n",
       "       [0.7778341 , 0.22216584],\n",
       "       [0.76667297, 0.23332709],\n",
       "       [0.5748259 , 0.42517415],\n",
       "       [0.47023806, 0.52976197],\n",
       "       [0.1668583 , 0.8331417 ],\n",
       "       [0.6415442 , 0.35845572],\n",
       "       [0.47023806, 0.52976197],\n",
       "       [0.30566803, 0.694332  ],\n",
       "       [0.17751843, 0.8224816 ],\n",
       "       [0.77469105, 0.22530892],\n",
       "       [0.2219027 , 0.77809733],\n",
       "       [0.18118857, 0.8188115 ],\n",
       "       [0.77626646, 0.2237335 ],\n",
       "       [0.7776699 , 0.22233008],\n",
       "       [0.77683985, 0.22316015],\n",
       "       [0.24299812, 0.7570019 ],\n",
       "       [0.7406944 , 0.25930554],\n",
       "       [0.44702697, 0.55297303],\n",
       "       [0.26799503, 0.732005  ],\n",
       "       [0.6627503 , 0.33724973],\n",
       "       [0.33621708, 0.66378295],\n",
       "       [0.56336194, 0.4366381 ],\n",
       "       [0.5052657 , 0.49473426],\n",
       "       [0.4586101 , 0.54138994],\n",
       "       [0.7495722 , 0.25042784],\n",
       "       [0.295837  , 0.704163  ],\n",
       "       [0.3258646 , 0.6741354 ],\n",
       "       [0.71286273, 0.2871372 ],\n",
       "       [0.28619176, 0.71380824],\n",
       "       [0.22814655, 0.77185345],\n",
       "       [0.7636065 , 0.23639359],\n",
       "       [0.77469105, 0.22530892],\n",
       "       [0.61976993, 0.38023016],\n",
       "       [0.2767481 , 0.7232519 ],\n",
       "       [0.7776699 , 0.22233008],\n",
       "       [0.77683985, 0.22316015],\n",
       "       [0.7495722 , 0.25042784],\n",
       "       [0.36820015, 0.6317998 ],\n",
       "       [0.5169471 , 0.4830529 ],\n",
       "       [0.5748259 , 0.42517415],\n",
       "       [0.52861   , 0.47138998],\n",
       "       [0.21292223, 0.7870778 ],\n",
       "       [0.7778341 , 0.22216584],\n",
       "       [0.71286273, 0.2871372 ],\n",
       "       [0.5052657 , 0.4947343 ],\n",
       "       [0.60869277, 0.3913072 ],\n",
       "       [0.7743543 , 0.22564568],\n",
       "       [0.16004008, 0.83996   ],\n",
       "       [0.2219027 , 0.77809733],\n",
       "       [0.67311895, 0.3268811 ],\n",
       "       [0.776831  , 0.223169  ],\n",
       "       [0.5169471 , 0.4830529 ],\n",
       "       [0.42404452, 0.57595545],\n",
       "       [0.68332106, 0.31667897],\n",
       "       [0.2086992 , 0.7913008 ],\n",
       "       [0.1668583 , 0.8331417 ],\n",
       "       [0.61976993, 0.38023016],\n",
       "       [0.30566803, 0.694332  ],\n",
       "       [0.3258646 , 0.6741354 ],\n",
       "       [0.401386  , 0.59861404],\n",
       "       [0.26799503, 0.732005  ],\n",
       "       [0.22814655, 0.77185345],\n",
       "       [0.412669  , 0.587331  ],\n",
       "       [0.2767481 , 0.7232519 ],\n",
       "       [0.6522227 , 0.34777725],\n",
       "       [0.28619176, 0.71380824],\n",
       "       [0.18870538, 0.8112946 ],\n",
       "       [0.5518299 , 0.44817016],\n",
       "       [0.30566803, 0.694332  ],\n",
       "       [0.70319897, 0.29680103],\n",
       "       [0.7723132 , 0.22768682],\n",
       "       [0.37914118, 0.6208588 ],\n",
       "       [0.18118857, 0.8188115 ],\n",
       "       [0.48189846, 0.51810163],\n",
       "       [0.6731189 , 0.3268811 ],\n",
       "       [0.77547973, 0.22452024],\n",
       "       [0.77547973, 0.22452024],\n",
       "       [0.7739004 , 0.22609961],\n",
       "       [0.2767481 , 0.7232519 ],\n",
       "       [0.7406944 , 0.25930554],\n",
       "       [0.7406944 , 0.25930554],\n",
       "       [0.7739004 , 0.22609961],\n",
       "       [0.21720725, 0.7827928 ],\n",
       "       [0.7406944 , 0.25930554],\n",
       "       [0.7743543 , 0.22564565],\n",
       "       [0.18870538, 0.8112946 ],\n",
       "       [0.77683985, 0.22316015],\n",
       "       [0.42404452, 0.57595545],\n",
       "       [0.7316147 , 0.26838532],\n",
       "       [0.56336194, 0.4366381 ],\n",
       "       [0.39020652, 0.6097935 ],\n",
       "       [0.7406944 , 0.25930554],\n",
       "       [0.2045382 , 0.79546183],\n",
       "       [0.7778341 , 0.22216584],\n",
       "       [0.2594194 , 0.74058056],\n",
       "       [0.77626646, 0.2237335 ],\n",
       "       [0.58620995, 0.4137901 ],\n",
       "       [0.2353095 , 0.76469046],\n",
       "       [0.33621708, 0.66378295],\n",
       "       [0.76667297, 0.23332709],\n",
       "       [0.7697059 , 0.23029412],\n",
       "       [0.7743543 , 0.22564568],\n",
       "       [0.20043911, 0.79956084],\n",
       "       [0.2219027 , 0.77809733],\n",
       "       [0.4586101 , 0.54138994],\n",
       "       [0.7636065 , 0.23639356],\n",
       "       [0.3258646 , 0.6741354 ],\n",
       "       [0.58620995, 0.4137901 ],\n",
       "       [0.18491744, 0.81508255],\n",
       "       [0.7778341 , 0.22216584],\n",
       "       [0.18491744, 0.81508255],\n",
       "       [0.7743543 , 0.22564568],\n",
       "       [0.15344909, 0.84655094],\n",
       "       [0.37914118, 0.6208588 ],\n",
       "       [0.2219027 , 0.77809733],\n",
       "       [0.7697059 , 0.23029412]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                         normalization=False,\n",
    "                         title='Confusion Matrix',\n",
    "                         cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This is function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting 'True'.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalization:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalization confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"red\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[84 26]\n",
      " [18 72]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f242c6f1b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['positive', 'negetive']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Model\n",
    "## 1. model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function saves:\n",
    "* The architecture of the model, allowing to recreate the model\n",
    "* The weights of the model\n",
    "* The training configuration(loss, optimizer)\n",
    "* The state of thte optimizer, allowing to resume training exactly where you left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('first_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.47651103, -0.17376271, -0.33923426, -0.2947242 ,  0.41391018,\n",
       "         -0.5605991 , -0.46536398,  0.71695   ,  0.32736814, -0.00592934,\n",
       "         -0.49973375, -0.03224009,  0.6212056 ,  0.2073852 ,  0.15997186,\n",
       "         -0.09088755]], dtype=float32),\n",
       " array([-0.08661903,  0.        ,  0.        ,  0.        , -0.08015214,\n",
       "         0.        ,  0.        ,  0.09176162, -0.06118227,  0.12131497,\n",
       "         0.        ,  0.        , -0.06317133, -0.03834474, -0.02281619,\n",
       "         0.        ], dtype=float32),\n",
       " array([[-0.03096911, -0.31696308, -0.04708217, -0.1904664 ,  0.38220254,\n",
       "         -0.1713376 ,  0.07629566, -0.34834242,  0.01621759,  0.17669581,\n",
       "         -0.27421743, -0.05063207, -0.43917105,  0.08256012, -0.31861347,\n",
       "         -0.2663218 , -0.29729748, -0.30591297,  0.26595768, -0.11703858,\n",
       "         -0.26540518,  0.28171176,  0.01401495,  0.14627863, -0.21207206,\n",
       "         -0.01018673,  0.486882  , -0.11921033,  0.06834646, -0.24159761,\n",
       "         -0.09411615, -0.32649088],\n",
       "        [-0.16653779, -0.22286116,  0.3010219 , -0.0032528 ,  0.21338037,\n",
       "         -0.08757913,  0.13077527,  0.01138708, -0.34318745,  0.09438467,\n",
       "         -0.3120497 ,  0.00067368,  0.05145255,  0.07538673,  0.2234954 ,\n",
       "          0.07789075, -0.09831116, -0.19498928, -0.17655255, -0.17789637,\n",
       "          0.0280903 ,  0.3096197 ,  0.32694462,  0.28990868,  0.11837608,\n",
       "          0.24581221,  0.00103927, -0.01560816, -0.2627078 ,  0.2261835 ,\n",
       "         -0.23296763,  0.05206668],\n",
       "        [-0.19175762,  0.1862767 , -0.2778443 , -0.11691587,  0.01767495,\n",
       "         -0.06709695,  0.13934726,  0.09874466,  0.1616796 ,  0.08166322,\n",
       "          0.05894059, -0.04769978,  0.17987236, -0.35123682,  0.06120211,\n",
       "          0.29058644,  0.16829947, -0.02622521, -0.27348533,  0.2750955 ,\n",
       "          0.3179414 , -0.21467657, -0.00541046, -0.25236714,  0.05809605,\n",
       "          0.3125315 ,  0.32597145,  0.13309982,  0.31788823,  0.16126844,\n",
       "         -0.30434197, -0.04405272],\n",
       "        [ 0.2692934 ,  0.31595686, -0.07321405, -0.3493462 ,  0.10809106,\n",
       "          0.22871098, -0.17481628, -0.08066484, -0.2409387 ,  0.15163246,\n",
       "         -0.11466657, -0.24000818,  0.33406857,  0.334613  ,  0.2273657 ,\n",
       "         -0.07274696, -0.28337687,  0.20927122, -0.14908664, -0.17508298,\n",
       "          0.09637383,  0.12361619, -0.25314307, -0.18945193,  0.28016934,\n",
       "         -0.342591  , -0.09203196,  0.23406199, -0.3154888 ,  0.07573223,\n",
       "          0.26336   , -0.0606949 ],\n",
       "        [-0.18680222, -0.36991483,  0.20173176, -0.28113043,  0.37088016,\n",
       "          0.35403112,  0.24046615, -0.30421054,  0.09498897,  0.06460178,\n",
       "          0.05784935,  0.20248975, -0.15592925, -0.08034429,  0.3410149 ,\n",
       "         -0.04583815,  0.04090104, -0.04191799,  0.26440093, -0.2518312 ,\n",
       "          0.13879159, -0.28964284, -0.16898297, -0.3902315 , -0.15386306,\n",
       "         -0.24209182, -0.20546648, -0.18510853,  0.36151662, -0.31837547,\n",
       "         -0.30352545, -0.22525458],\n",
       "        [-0.3280225 , -0.09165531, -0.04686123, -0.19508865, -0.27848488,\n",
       "         -0.24218446,  0.14479408,  0.04960263, -0.13527428, -0.19355468,\n",
       "          0.19004598, -0.05164683, -0.00924534,  0.32917657,  0.34734568,\n",
       "         -0.03235134, -0.28966963,  0.12878424, -0.20081498,  0.06798077,\n",
       "         -0.09674698,  0.22874698, -0.1868148 , -0.06463498, -0.17991866,\n",
       "         -0.03631666, -0.14290419,  0.35118875, -0.23423398, -0.21230042,\n",
       "          0.13280237, -0.0263288 ],\n",
       "        [ 0.01150322,  0.16277012,  0.23381713, -0.1232512 ,  0.1754457 ,\n",
       "          0.05969813,  0.10956907, -0.2716968 , -0.17754689, -0.11161412,\n",
       "         -0.2612189 ,  0.2139031 , -0.05411083,  0.12137079, -0.04612508,\n",
       "         -0.2666583 ,  0.1982424 ,  0.09494007, -0.20216848, -0.32242668,\n",
       "          0.3327357 , -0.31963587,  0.0026007 , -0.17409986,  0.02662468,\n",
       "         -0.11616868,  0.12125117, -0.13060272, -0.04627529,  0.35202935,\n",
       "         -0.13601504,  0.11373225],\n",
       "        [ 0.20690279,  0.23394014, -0.13788976, -0.24640301,  0.30978835,\n",
       "         -0.01238519,  0.36800215, -0.23612122, -0.152264  ,  0.10221207,\n",
       "          0.1636946 ,  0.08891653,  0.00963886, -0.27192283, -0.08453655,\n",
       "         -0.27935755,  0.13253066, -0.23226379, -0.08482052,  0.15624782,\n",
       "         -0.22353753,  0.06648839,  0.28493765,  0.09073818, -0.03649929,\n",
       "          0.13410784,  0.36511686,  0.07995008,  0.27775177,  0.11724566,\n",
       "          0.04631767, -0.01029346],\n",
       "        [ 0.12464791,  0.00320253,  0.29223824,  0.27586383,  0.43406755,\n",
       "          0.25327447,  0.5137057 ,  0.15984985, -0.06556237, -0.43194842,\n",
       "         -0.4165502 , -0.1086771 , -0.17355874, -0.2717046 , -0.0573479 ,\n",
       "          0.08898529,  0.13952194,  0.22527365, -0.23812476, -0.209689  ,\n",
       "         -0.00914785,  0.3114316 , -0.05597686, -0.27248162, -0.0895213 ,\n",
       "          0.19577014,  0.47530767, -0.17554452,  0.12560411, -0.4000514 ,\n",
       "         -0.30090806, -0.1504047 ],\n",
       "        [-0.13000198, -0.08903483, -0.13977481, -0.21066017,  0.11819627,\n",
       "         -0.125796  ,  0.07291157,  0.00966099, -0.13592805,  0.06890109,\n",
       "          0.23517534,  0.25182614,  0.35219985,  0.30375037, -0.22690657,\n",
       "          0.20813406,  0.25661516,  0.332614  ,  0.04852065,  0.12801918,\n",
       "          0.18185142,  0.03820903, -0.08356009,  0.21347407, -0.16904923,\n",
       "         -0.20394568,  0.14114769, -0.23210344, -0.06040001, -0.02911717,\n",
       "          0.26222873, -0.26717973],\n",
       "        [ 0.32995746,  0.17464724,  0.06513745,  0.3127629 , -0.1352714 ,\n",
       "          0.05149519,  0.14139786,  0.10717234,  0.02074629, -0.21630436,\n",
       "         -0.1743659 ,  0.10935724,  0.12724799,  0.11929345, -0.30003574,\n",
       "          0.32542077,  0.27186063,  0.31746987, -0.07441851,  0.24551609,\n",
       "          0.19069687,  0.08491468,  0.14641014, -0.21989495,  0.1722379 ,\n",
       "          0.02398813,  0.20666906,  0.08717948,  0.16232285, -0.15675509,\n",
       "         -0.30665666,  0.10657877],\n",
       "        [-0.30962735, -0.30967936,  0.32459083,  0.03372633, -0.176344  ,\n",
       "          0.03653279,  0.02659619, -0.25205255, -0.28525114, -0.282732  ,\n",
       "         -0.10007551,  0.30197135, -0.34947467,  0.2635965 ,  0.34396175,\n",
       "         -0.2601579 ,  0.01065168, -0.03915873, -0.32153282, -0.3034374 ,\n",
       "         -0.03182095, -0.02716869, -0.2609361 ,  0.12844825, -0.34129244,\n",
       "          0.27623907,  0.30577144, -0.29994893,  0.28668085,  0.01841751,\n",
       "          0.1165984 ,  0.07374325],\n",
       "        [ 0.4601861 , -0.20848297, -0.00226068,  0.14618069, -0.1593967 ,\n",
       "          0.46985215,  0.10620142, -0.19115357, -0.03048506, -0.15674505,\n",
       "         -0.23904717, -0.22043768,  0.0755885 , -0.1709788 ,  0.10672124,\n",
       "         -0.19972602, -0.29006952,  0.10272858, -0.20079367, -0.31001085,\n",
       "          0.121494  ,  0.36633104,  0.37399936, -0.11375864,  0.07689288,\n",
       "          0.0638512 ,  0.08560175, -0.13273713,  0.15716408, -0.00860999,\n",
       "         -0.26096544,  0.09592713],\n",
       "        [ 0.32240936, -0.00882258,  0.08384907,  0.27861232,  0.16610792,\n",
       "          0.2563358 , -0.15733828, -0.07429671,  0.33935192, -0.4381613 ,\n",
       "         -0.24391042, -0.14045456, -0.22546515, -0.17225881,  0.13232931,\n",
       "         -0.04795992,  0.25837013, -0.45339122, -0.16667138,  0.11671267,\n",
       "          0.03600335,  0.21037881,  0.49098104, -0.01099806, -0.24065706,\n",
       "          0.14574039, -0.00948941, -0.16851455,  0.03664897, -0.17133929,\n",
       "          0.37643084, -0.06004754],\n",
       "        [ 0.20279385,  0.07985532,  0.02064034, -0.15594986,  0.10106067,\n",
       "          0.1920057 , -0.12071563, -0.24430463, -0.32961947, -0.1908786 ,\n",
       "         -0.01109826, -0.4157501 ,  0.17914733,  0.18892601,  0.01670356,\n",
       "          0.17408784,  0.14992858, -0.02660547,  0.09885861, -0.20255803,\n",
       "          0.29528168, -0.22115278,  0.43241704, -0.18843454,  0.28061047,\n",
       "         -0.47124955,  0.1504554 ,  0.22373208,  0.43048263,  0.19702277,\n",
       "          0.06013443,  0.29363763],\n",
       "        [-0.09034169, -0.11164203, -0.1762507 ,  0.28337625, -0.15730207,\n",
       "         -0.20205958, -0.06231809, -0.02219614, -0.24876857, -0.3071852 ,\n",
       "         -0.11367351, -0.3334806 ,  0.02186063, -0.02175039, -0.11263113,\n",
       "         -0.1749047 , -0.18145448, -0.2137576 ,  0.03857508, -0.11897844,\n",
       "         -0.00498497,  0.31825706,  0.24588558,  0.24469212, -0.03168905,\n",
       "         -0.03968546, -0.02850357,  0.09828511,  0.14618045,  0.00896338,\n",
       "          0.11403808, -0.29378545]], dtype=float32),\n",
       " array([-0.03940902,  0.11944213, -0.01998489,  0.00441639, -0.06668063,\n",
       "        -0.0158614 , -0.06576528,  0.        ,  0.        ,  0.07487782,\n",
       "         0.14306587,  0.06095245,  0.12898263, -0.01190931, -0.00065856,\n",
       "        -0.00247612, -0.0527925 ,  0.17416005, -0.00756446,  0.15829185,\n",
       "        -0.00292699, -0.02516374, -0.04903504,  0.08827768, -0.00124546,\n",
       "         0.0497633 , -0.06646623, -0.00293563, -0.05297511,  0.15250969,\n",
       "         0.13194524, -0.00118752], dtype=float32),\n",
       " array([[-0.4951847 ,  0.4159203 ],\n",
       "        [ 0.04820506, -0.6554419 ],\n",
       "        [ 0.03009296, -0.32312793],\n",
       "        [ 0.03125924, -0.24596317],\n",
       "        [-0.41332048, -0.10078996],\n",
       "        [-0.5843765 ,  0.0055484 ],\n",
       "        [ 0.08243813,  0.5110991 ],\n",
       "        [-0.18295518, -0.19251274],\n",
       "        [-0.40043086,  0.00775465],\n",
       "        [ 0.02588623, -0.35555163],\n",
       "        [ 0.2900255 , -0.54812604],\n",
       "        [ 0.35093418,  0.08108593],\n",
       "        [ 0.3505735 , -0.592726  ],\n",
       "        [-0.063087  ,  0.23555686],\n",
       "        [ 0.33225238, -0.40817732],\n",
       "        [ 0.24301615,  0.26209906],\n",
       "        [-0.16454694,  0.00691618],\n",
       "        [ 0.0966528 , -0.54154676],\n",
       "        [ 0.10794587, -0.00143712],\n",
       "        [ 0.28129843, -0.58381945],\n",
       "        [-0.30155107,  0.41768765],\n",
       "        [-0.24737857, -0.12253085],\n",
       "        [-0.47320887,  0.19039655],\n",
       "        [ 0.45910406, -0.5025668 ],\n",
       "        [ 0.05167057,  0.28276318],\n",
       "        [-0.19097678, -0.29950368],\n",
       "        [-0.48904622,  0.16222508],\n",
       "        [-0.3394178 ,  0.07833433],\n",
       "        [-0.41952989, -0.10492297],\n",
       "        [-0.02547356, -0.6155425 ],\n",
       "        [ 0.35070404, -0.3780105 ],\n",
       "        [-0.25146526,  0.31948382]], dtype=float32),\n",
       " array([ 0.06190269, -0.06190268], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x7f242cc737b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. model.to_json()\n",
    "If you only need to save the architecture of a model, and not its weights of its training configuration, you cna use the following function to save the architecture only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as json\n",
    "json_string = model.to_json()\n",
    "\n",
    "#save as YAML\n",
    "#yaml_string = model._to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"keras_version\": \"2.1.5\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reconstruction from JSON:\n",
    "from keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)\n",
    "\n",
    "# model reconstruction from YAML\n",
    "# from keras.models import model_from_yaml\n",
    "# model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.09147066,  0.4825759 , -0.40045184, -0.18272778,  0.15849924,\n",
       "          0.33471602,  0.03200525, -0.591152  ,  0.10870922,  0.49889052,\n",
       "         -0.56499845,  0.15621752,  0.02770132,  0.0323205 , -0.4241336 ,\n",
       "          0.48310125]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 6.38964772e-02, -2.00212002e-04,  2.65782386e-01,\n",
       "          1.81316048e-01,  1.86899155e-01, -1.87695429e-01,\n",
       "         -3.35858613e-01,  8.70880187e-02,  3.22444469e-01,\n",
       "         -1.92692772e-01, -2.32970238e-01,  3.24725360e-01,\n",
       "          3.09752256e-01,  1.32241815e-01,  3.15681010e-01,\n",
       "          2.26158887e-01, -3.49143744e-01, -2.02133328e-01,\n",
       "          1.07892811e-01, -2.09387481e-01,  1.07752293e-01,\n",
       "         -2.81223595e-01,  1.47624284e-01, -2.62450367e-01,\n",
       "          2.85611898e-01, -1.75482959e-01, -8.68919790e-02,\n",
       "          1.19855613e-01,  1.79767281e-01,  1.07814431e-01,\n",
       "         -1.73050240e-01,  3.47981244e-01],\n",
       "        [-1.11308470e-01,  3.53197008e-01, -1.16943926e-01,\n",
       "          2.28456050e-01, -9.12865996e-03, -9.49119925e-02,\n",
       "         -1.62045270e-01,  2.34567851e-01, -3.38780582e-02,\n",
       "          2.70336121e-01,  2.58138746e-01, -3.02739114e-01,\n",
       "         -7.95740783e-02, -3.06856453e-01, -2.71770358e-02,\n",
       "         -5.55868149e-02,  2.50658959e-01, -2.66705692e-01,\n",
       "          1.50738955e-02, -1.38655037e-01,  8.51684213e-02,\n",
       "         -1.56217203e-01,  2.18544751e-01, -1.21797308e-01,\n",
       "          8.74918699e-03, -2.98949122e-01,  2.35985368e-01,\n",
       "         -2.33209044e-01,  6.29744828e-02,  3.08438450e-01,\n",
       "          2.14606971e-01,  2.78958112e-01],\n",
       "        [-3.37758064e-02, -1.71407863e-01, -2.68527925e-01,\n",
       "         -1.64073035e-01,  3.42902452e-01, -2.95144767e-01,\n",
       "         -7.12426007e-02,  2.61640459e-01, -2.64690638e-01,\n",
       "         -1.21728018e-01, -2.56912947e-01,  3.12159508e-01,\n",
       "          1.28344238e-01, -2.96546817e-01,  7.07629621e-02,\n",
       "         -2.81319916e-01, -2.45675743e-01, -3.32905233e-01,\n",
       "          1.38514280e-01, -3.11784089e-01,  3.53132576e-01,\n",
       "         -3.40442091e-01,  1.76643401e-01, -3.52541536e-01,\n",
       "          3.50623578e-01,  2.61757970e-02, -2.28880137e-01,\n",
       "          2.49714524e-01, -8.60139728e-02,  3.53199273e-01,\n",
       "          3.05381566e-01, -1.67931587e-01],\n",
       "        [-2.19904974e-01, -8.71449411e-02, -3.25414389e-01,\n",
       "         -3.33940178e-01,  3.38046998e-01,  8.81387591e-02,\n",
       "          3.13432962e-01, -2.68615246e-01, -2.87246108e-01,\n",
       "          1.47529572e-01,  9.26605165e-02, -2.87622631e-01,\n",
       "          2.82047659e-01, -2.94272244e-01, -2.19237193e-01,\n",
       "         -1.49727181e-01, -1.24090016e-01, -3.14754605e-01,\n",
       "         -7.78075457e-02, -3.31555426e-01, -4.82013226e-02,\n",
       "         -5.09648025e-02,  1.05826110e-01,  4.45687771e-02,\n",
       "         -1.88118219e-02,  3.47235203e-02, -2.25348324e-01,\n",
       "         -1.68267161e-01, -2.61282802e-01,  1.55011207e-01,\n",
       "          1.41058236e-01, -3.01523447e-01],\n",
       "        [ 1.14846826e-02, -1.10640958e-01, -2.62342215e-01,\n",
       "          6.84935153e-02,  2.31827289e-01, -2.45663851e-01,\n",
       "          4.20616269e-02, -6.71970844e-02,  1.19528532e-01,\n",
       "          2.19934136e-01, -1.41549006e-01, -2.35052794e-01,\n",
       "          8.54923427e-02, -2.86892593e-01,  1.83206171e-01,\n",
       "          2.88418859e-01, -3.22885573e-01, -1.72829464e-01,\n",
       "         -7.41524994e-02, -2.36452922e-01, -2.31702551e-01,\n",
       "          1.89998299e-01,  2.33100027e-01,  1.47777647e-01,\n",
       "         -1.53667495e-01,  1.94348246e-01, -2.84342945e-01,\n",
       "         -1.10699028e-01, -2.32979655e-03, -7.83486366e-02,\n",
       "         -2.91275173e-01,  1.43801928e-01],\n",
       "        [-1.88851595e-01,  3.39235991e-01,  1.45295262e-02,\n",
       "         -2.51828432e-01,  9.18284655e-02,  1.42600536e-02,\n",
       "          2.66975164e-03, -2.32471734e-01,  1.44735634e-01,\n",
       "          3.34409624e-01,  1.71700418e-02,  5.81343174e-02,\n",
       "          3.49675983e-01, -7.13387132e-03,  2.03779727e-01,\n",
       "         -1.10990599e-01,  2.57853836e-01, -2.12946028e-01,\n",
       "          2.85053402e-01, -2.00803429e-01,  1.28200859e-01,\n",
       "         -6.18768930e-02, -2.90852368e-01, -7.61585236e-02,\n",
       "         -1.38261884e-01,  1.20918393e-01,  2.98428446e-01,\n",
       "         -4.20369208e-02,  8.58797729e-02, -1.43677890e-02,\n",
       "          1.39573067e-01,  1.07044637e-01],\n",
       "        [ 2.30416983e-01, -4.22667861e-02, -1.49816960e-01,\n",
       "          3.41971010e-01, -1.85706005e-01, -2.99094528e-01,\n",
       "         -5.78099787e-02, -1.92939416e-01,  2.34023303e-01,\n",
       "          3.37574869e-01, -2.39288807e-01,  1.02871865e-01,\n",
       "          8.39539170e-02, -3.42121899e-01, -3.50365400e-01,\n",
       "         -2.45571554e-01, -2.42967904e-01,  8.18810463e-02,\n",
       "          3.00593972e-02, -1.38835251e-01,  1.64336473e-01,\n",
       "         -1.23155534e-01, -2.25514174e-02,  2.91773945e-01,\n",
       "         -3.00668031e-01,  3.27229291e-01,  2.81488746e-01,\n",
       "         -2.46203929e-01, -2.16591954e-02, -2.97076523e-01,\n",
       "          1.62523657e-01, -9.06578600e-02],\n",
       "        [-1.64115027e-01, -1.75779328e-01, -7.65246749e-02,\n",
       "         -1.03226662e-01,  2.11056858e-01,  2.14454263e-01,\n",
       "         -1.50142074e-01,  1.14552259e-01, -2.18543887e-01,\n",
       "         -1.09641656e-01, -3.28498691e-01, -1.87260464e-01,\n",
       "         -3.26015055e-02, -1.52909949e-01,  2.76965052e-01,\n",
       "          1.54817671e-01,  2.69664556e-01, -1.96856126e-01,\n",
       "          6.95702732e-02,  9.35289264e-03,  2.38417476e-01,\n",
       "         -1.38647854e-02,  7.65999556e-02, -7.04114437e-02,\n",
       "          1.62937433e-01, -1.75949007e-01,  1.69995517e-01,\n",
       "         -2.64971167e-01, -3.07903796e-01,  9.51515734e-02,\n",
       "         -1.38484433e-01, -1.64455906e-01],\n",
       "        [ 9.45676565e-02, -7.41078854e-02,  2.76781887e-01,\n",
       "         -6.61616921e-02, -2.66762674e-01, -1.29170135e-01,\n",
       "         -1.40968144e-01, -2.56058127e-01, -3.39634210e-01,\n",
       "          4.65243757e-02,  2.79054254e-01, -6.54693842e-02,\n",
       "         -6.41607344e-02, -9.98474061e-02,  2.51473278e-01,\n",
       "          3.36321145e-01, -7.77533352e-02, -1.39663354e-01,\n",
       "         -1.17303133e-02, -3.58614028e-02, -6.11430109e-02,\n",
       "          3.36850852e-01, -4.51599360e-02,  3.34354669e-01,\n",
       "          5.28092384e-02, -2.91672200e-01, -5.12531698e-02,\n",
       "         -3.45051944e-01,  3.26857001e-01,  3.32654119e-02,\n",
       "         -3.09728414e-01,  9.55356061e-02],\n",
       "        [ 3.82195115e-02, -2.77506649e-01, -2.03116283e-01,\n",
       "          2.59703368e-01, -1.06523633e-01,  1.43067569e-01,\n",
       "         -2.27497131e-01,  1.54308289e-01, -1.33604333e-01,\n",
       "          1.09777361e-01, -4.47546542e-02,  2.91580468e-01,\n",
       "         -1.90482423e-01, -2.47660443e-01, -1.74586073e-01,\n",
       "          7.45420158e-02,  2.66189903e-01,  1.42420262e-01,\n",
       "         -1.45949230e-01, -2.80030668e-01, -2.85714507e-01,\n",
       "          1.55275673e-01,  3.24110717e-01, -8.09328258e-02,\n",
       "         -2.36071914e-01, -1.71032250e-01, -2.53507316e-01,\n",
       "         -6.16907477e-02,  1.67659134e-01, -1.73378989e-01,\n",
       "          1.85444206e-01,  1.40241086e-02],\n",
       "        [ 2.32919186e-01, -1.57749504e-01, -7.83898532e-02,\n",
       "          5.32106459e-02, -2.18413055e-01,  3.44292372e-01,\n",
       "          1.43588245e-01, -4.33155894e-02, -3.21199536e-01,\n",
       "         -2.32595801e-02, -3.87775898e-03,  1.58869833e-01,\n",
       "         -2.16259688e-01,  1.02342665e-02, -2.17024982e-02,\n",
       "          3.43331248e-01, -1.27809480e-01, -3.46422553e-01,\n",
       "          2.37397879e-01, -3.01498175e-02,  1.11629367e-02,\n",
       "         -6.57877326e-03,  1.02166831e-01,  2.11870462e-01,\n",
       "          1.83208495e-01,  1.31565332e-03,  3.19961101e-01,\n",
       "         -2.44101882e-02, -2.89406806e-01,  2.83631682e-03,\n",
       "         -1.74362853e-01,  2.88280874e-01],\n",
       "        [ 3.15660685e-01,  1.97390646e-01, -3.45531404e-01,\n",
       "          5.75241148e-02, -3.29153895e-01,  1.16790771e-01,\n",
       "          2.92132705e-01, -8.35514963e-02,  1.18837357e-02,\n",
       "         -1.02606177e-01, -3.38519216e-02, -2.14926898e-02,\n",
       "          2.42094547e-01,  1.39945149e-01, -9.27358866e-02,\n",
       "         -2.48225540e-01, -2.61695772e-01, -3.26747328e-01,\n",
       "         -3.48039240e-01, -3.12718749e-02, -2.09753066e-01,\n",
       "          5.62515855e-03,  1.79281741e-01, -1.16831154e-01,\n",
       "         -1.42376691e-01,  3.07545632e-01, -1.43427238e-01,\n",
       "          3.01797479e-01, -6.56817257e-02,  1.97985679e-01,\n",
       "         -1.79585278e-01,  2.68379003e-01],\n",
       "        [-3.46297473e-01,  3.59328091e-02, -6.62955642e-02,\n",
       "          3.06192070e-01, -7.55754411e-02,  2.58223623e-01,\n",
       "          3.35184425e-01, -6.47658110e-02,  2.35268682e-01,\n",
       "          1.07206404e-02,  6.97290003e-02,  3.40909064e-02,\n",
       "          1.65066689e-01,  4.35816050e-02, -6.20835721e-02,\n",
       "         -6.03337288e-02, -2.51754254e-01,  1.89696252e-02,\n",
       "         -2.05545291e-01, -1.19054392e-01, -3.41308206e-01,\n",
       "         -5.93647659e-02, -7.22793043e-02,  1.17830873e-01,\n",
       "          1.90304369e-01, -2.55871236e-01, -9.79146361e-03,\n",
       "         -3.32795799e-01, -1.39284208e-01, -2.80776739e-01,\n",
       "          2.81080604e-02, -9.39387083e-03],\n",
       "        [ 1.18775129e-01, -6.32566214e-03,  2.28774339e-01,\n",
       "          2.64156014e-01,  2.14711577e-01,  7.14599788e-02,\n",
       "          1.01161122e-01, -4.46496010e-02, -2.11226091e-01,\n",
       "         -2.96586871e-01,  5.69007695e-02,  1.08813733e-01,\n",
       "          2.93123722e-02, -1.65124774e-01,  1.98044389e-01,\n",
       "          3.02512735e-01,  1.02413386e-01, -2.89481759e-01,\n",
       "          3.19595486e-01, -2.97731727e-01, -1.53117135e-01,\n",
       "         -2.60534346e-01, -2.91677862e-01,  3.91939282e-03,\n",
       "         -2.70721763e-01, -5.23732603e-02,  1.85854167e-01,\n",
       "         -1.75156400e-01,  1.32863969e-01,  8.63988400e-02,\n",
       "         -3.35932642e-01,  2.43307054e-02],\n",
       "        [-1.57515332e-01, -1.77797571e-01, -1.19834706e-01,\n",
       "         -1.20964736e-01,  1.24145746e-01,  1.67452186e-01,\n",
       "         -3.69217396e-02, -1.98566109e-01,  2.52476126e-01,\n",
       "         -1.84979558e-01, -2.92698890e-01,  3.49061042e-01,\n",
       "          2.53165156e-01,  1.88710302e-01,  2.71391422e-01,\n",
       "          8.76514614e-02,  3.26877266e-01, -1.78954840e-01,\n",
       "          1.28761411e-01,  5.87280989e-02,  7.49247968e-02,\n",
       "         -1.19894043e-01,  1.84771717e-02, -9.03776884e-02,\n",
       "         -3.46579760e-01,  2.11124152e-01, -1.68013602e-01,\n",
       "         -4.98185158e-02, -2.52662182e-01,  2.52909571e-01,\n",
       "          1.93443805e-01, -6.96019828e-02],\n",
       "        [-2.66231865e-01,  3.24834287e-02, -8.79514515e-02,\n",
       "         -3.07834268e-01,  1.04953080e-01,  1.41476780e-01,\n",
       "         -2.74054915e-01,  1.41361803e-01,  1.59010619e-01,\n",
       "          3.06003690e-02,  8.24481249e-04, -3.45435828e-01,\n",
       "          3.06560844e-01, -5.06134629e-02,  9.56386030e-02,\n",
       "          1.14490390e-01, -2.18945459e-01,  2.89028257e-01,\n",
       "          5.04034162e-02, -9.75400209e-02,  7.31611252e-02,\n",
       "          3.00647706e-01, -1.77292913e-01,  7.69730508e-02,\n",
       "         -9.88729596e-02,  1.83261663e-01,  2.04949051e-01,\n",
       "         -3.16480696e-01,  1.42322391e-01,  3.51906389e-01,\n",
       "          5.31765819e-02,  2.16565758e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 0.02204311,  0.02028847],\n",
       "        [-0.25044307, -0.21538442],\n",
       "        [-0.2259692 , -0.1644127 ],\n",
       "        [-0.02179542, -0.27826035],\n",
       "        [ 0.18225065,  0.3968574 ],\n",
       "        [ 0.02388316,  0.07485536],\n",
       "        [-0.4193068 , -0.249747  ],\n",
       "        [ 0.06532022,  0.18619439],\n",
       "        [ 0.38838372,  0.38604608],\n",
       "        [-0.3514242 , -0.095642  ],\n",
       "        [-0.33148617,  0.16579828],\n",
       "        [-0.17952614,  0.13735148],\n",
       "        [ 0.1831195 , -0.1821357 ],\n",
       "        [ 0.16389003, -0.06593651],\n",
       "        [ 0.2565172 ,  0.0720531 ],\n",
       "        [-0.0439038 , -0.05128619],\n",
       "        [ 0.28120932,  0.1035485 ],\n",
       "        [-0.02439216, -0.14660281],\n",
       "        [ 0.0591214 ,  0.06066719],\n",
       "        [-0.01237196, -0.2888851 ],\n",
       "        [-0.20317362,  0.21164152],\n",
       "        [-0.23028031, -0.19309996],\n",
       "        [ 0.35129198, -0.12112966],\n",
       "        [-0.10863724,  0.02114269],\n",
       "        [ 0.00847819, -0.04713565],\n",
       "        [ 0.08510783,  0.28929725],\n",
       "        [ 0.00569886, -0.2470533 ],\n",
       "        [ 0.00378659, -0.25138223],\n",
       "        [-0.3289349 , -0.11976275],\n",
       "        [-0.16981411,  0.26613912],\n",
       "        [-0.12758222, -0.15817681],\n",
       "        [ 0.25949356, -0.34644747]], dtype=float32),\n",
       " array([0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_architecture.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8c5098892bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_architecture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'optimizer'"
     ]
    }
   ],
   "source": [
    "model_architecture.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. model.save_weights()\n",
    "If you only need to save the weights of the model, yoiu can use the following save the weights only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('first_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('first_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
